# LLM Provider Selection
LLM_PROVIDER=openai  # Options: openai, anthropic, llamacpp, etc.

# Provider-specific API Credentials
## OpenAI
OPENAI_API_KEY=your_openai_key_here
OPENAI_ORGANIZATION_ID=your_org_id_here  # Optional
OPENAI_API_BASE_URL=https://api.openai.com/v1  # Optional, for custom endpoints

## Anthropic
ANTHROPIC_API_KEY=your_anthropic_key_here
ANTHROPIC_API_BASE_URL=https://api.anthropic.com  # Optional

## Local LLM (e.g., llama.cpp)
LLAMACPP_API_BASE_URL=http://localhost:8080  # Default for local llama.cpp server

# General LLM Configuration
LLM_MODEL=gpt-3.5-turbo  # Model name depends on provider
LLM_MAX_RETRIES=3
LLM_TEMPERATURE=0.7

# Other Settings
PLAYWRIGHT_ENABLED=true  # Enable/disable Playwright for JS-heavy pages 